{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pho2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7QLLVdlHffE0ojZ0jgezu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Petrichoeur/Neural_Net_from_scratch/blob/master/Pho2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puXqqwBQbkit",
        "colab_type": "code",
        "outputId": "3c0920a4-ca36-40bf-e7ab-b19d172212b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "PATH ='drive/My Drive/data'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mon Apr 27 23:12:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAQyRHAJcBze",
        "colab_type": "code",
        "outputId": "e7ee0ddd-ccb8-4b6d-fcf6-cc2ade04c844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import joblib\n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np  \n",
        "import tensorflow.compat.v1 as tf  \n",
        "import re \n",
        "import sys\n",
        "tf.disable_v2_behavior()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "from tqdm import trange \n",
        "from tqdm import tqdm_gui\n",
        "\n",
        "\n",
        "    \n",
        "def ipa_(x):\n",
        "\n",
        "  x=x.replace('ɑ̃','0')\n",
        "  x=x.replace('ɔ̃','1') \n",
        "  x=x.replace('ɛ̃', '2') \n",
        "  x=x.replace('œ̃','3') \n",
        "  x=x.replace('tr','4')\n",
        "  x=x.replace('kr','5')\n",
        "  x=x.replace('dr','6')\n",
        "  x=x.replace('gr','7') \n",
        "  x=x.replace('ʁ','r') \n",
        "  return x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkkE0A22cr91",
        "colab_type": "text"
      },
      "source": [
        "# Import data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDggwI9mcqIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQNg8l8fcp__",
        "colab_type": "code",
        "outputId": "c32d2061-94dd-42c9-9824-2224948b1c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "dfdic=joblib.load(PATH+'/phono/final_data.job') \n",
        "print('dfdic is original data ')\n",
        "\n",
        "for key in dfdic.keys():\n",
        "    dfdic[key]['valeur phono enfant']=dfdic[key]['valeur phono enfant'].apply(ipa_).apply(lambda x:list(x) )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dfdic is original data \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0FWRcBtcp0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4flpIbUt5ndU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWE83g-S5qZL",
        "colab_type": "text"
      },
      "source": [
        "# General way of making Pho2Vec with skip gram methodology  \n",
        "Inspired by this article : \n",
        "https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAGMCN71ckmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Pho2Vec():\n",
        "    \n",
        "    def __init__(self,data):\n",
        "        self.vocab=set(np.sum(data))\n",
        "        self.vocab_len= len(self.vocab) \n",
        "        self.vocab_len_input=self.vocab_len \n",
        "        self.vocab_len_output=self.vocab_len\n",
        "        self.model =None\n",
        "        self.data=data\n",
        "        self.pho_vec={}\n",
        "        self.pho2int={} \n",
        "        self.int2pho={}\n",
        "        self.history={}\n",
        "        self.vector_representation = None \n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.pho2int[word] = i\n",
        "            self.int2pho[i] = word\n",
        "    \n",
        "    \n",
        "    def dataforw2c(self,WORD,WINDOW_SIZE):\n",
        "        data = []\n",
        "        for talk in WORD:\n",
        "            for pho_index, pho in enumerate(talk):\n",
        "                iterab =talk[max(pho_index - WINDOW_SIZE, 0) : min(pho_index + WINDOW_SIZE, len(talk)) + 1]\n",
        "                for nb_pho in iterab : \n",
        "                    if nb_pho != pho:\n",
        "                        data.append([pho, nb_pho]) \n",
        "        return data \n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "        # function to convert numbers to one hot vectors\n",
        "    def __to_one_hot(self,data_point_index, vocab_len):\n",
        "        temp = np.zeros(vocab_len)\n",
        "        temp[data_point_index] = 1\n",
        "        return temp \n",
        "    def train_test(self,train_size=0.9,window_size=2): \n",
        "        \n",
        "        self.window_size=window_size\n",
        "        self.data_w2=self.dataforw2c(self.data , self.window_size)\n",
        "        \n",
        "        self.x = [] # input word\n",
        "        self.y= [] # output word\n",
        "        for data_word in self.data_w2:\n",
        "            self.x.append(self.__to_one_hot(self.pho2int[ data_word[0] ], self.vocab_len))\n",
        "            self.y.append(self.__to_one_hot(self.pho2int[ data_word[1] ], self.vocab_len))\n",
        "        # convert them to numpy arrays\n",
        "        self.x= np.asarray(self.x)\n",
        "        self.y= np.asarray(self.y) \n",
        "        \n",
        "        self.x_train,self.x_test,self.y_train,self.y_test =train_test_split(self.x,\n",
        "                                                                           self.y, \n",
        "                                                                           train_size=train_size)\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def model_2vecbow(self,embedding_dim=6,n_iter=10000): \n",
        "        try : \n",
        "            x_train = self.x_train \n",
        "            x_test  = self.x_test \n",
        "\n",
        "            y_train = self.y_train \n",
        "            y_test = self.y_test  \n",
        "        except : \n",
        "            AttributeError('train and test set must be initialize')\n",
        "        \n",
        "        \n",
        "        x = tf.placeholder(tf.float32, shape=(None, self.vocab_len_input))\n",
        "        y_label = tf.placeholder(tf.float32, shape=(None, self.vocab_len_output))   \n",
        "        \n",
        "        \n",
        "        self.embedding_dim=embedding_dim\n",
        "        EMBEDDING_DIM = embedding_dim\n",
        "        W1 = tf.Variable(tf.random_normal([self.vocab_len_input, EMBEDDING_DIM]))\n",
        "        b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM]))\n",
        "        \n",
        "\n",
        "        W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, self.vocab_len_output]))\n",
        "        b2 = tf.Variable(tf.random_normal([self.vocab_len_output]))\n",
        "        \n",
        "        def bow(val):\n",
        "            hidden_representation = tf.add(tf.matmul(val,W1), b1)\n",
        "            prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2)) \n",
        "            return prediction\n",
        "\n",
        "\n",
        "        cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(tf.clip_by_value(bow(x),1e-10,1.0)), reduction_indices=[1]))\n",
        "\n",
        "        sess = tf.Session()\n",
        "     \n",
        "       \n",
        "        Adam_opti=tf.train.AdamOptimizer(learning_rate=0.001,  beta1=0.9, beta2=0.999,   epsilon=1e-08, use_locking=False,name='Adam') \n",
        "        #train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)  \n",
        "        train_step=Adam_opti.minimize(cross_entropy_loss) \n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess.run(init) \n",
        "        \n",
        "       \n",
        "\n",
        "\n",
        "       \n",
        "        # train for n_iter iterations\n",
        "        self.history['loss']=[]\n",
        "        self.history['validation_loss']=[]\n",
        "\n",
        "        for i in range(n_iter):\n",
        " \n",
        "            \n",
        "            _,loss = sess.run([train_step,cross_entropy_loss], feed_dict={x: x_train, y_label: y_train}) \n",
        "\n",
        "            val_loss= cross_entropy_loss.eval(session=sess, feed_dict={x:x_test, y_label: y_test})  \n",
        "            self.history['loss'].append(loss) \n",
        "            self.history['validation_loss'].append(val_loss)\n",
        "        \n",
        "            if i % 10 == 0 : \n",
        "\n",
        "                try : \n",
        "                    sys.stdout.write(f'progression : {i} / {n_iter}  val loss={val_loss}  loss = {loss}') \n",
        "                    clear_output(wait=True)\n",
        "                except : \n",
        "                    sys.stdout.write(str_loss)\n",
        "                \n",
        "        \n",
        "            #tbar.refresh()\n",
        "        def get_pho_vectors(self): \n",
        "            try :\n",
        "                for key,val in self.pho2int.items():\n",
        "                    self.pho2vec[key]=vectors[val] \n",
        "            except : \n",
        "                AttributeError('train model_2vec first')\n",
        "            \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GoZmwO64Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltAVBV_od4_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Data4spec2vec(dfdic):\n",
        "\n",
        "    data_contain=[]\n",
        "    name= {}\n",
        "    idx=0\n",
        "    for key,df in dfdic.items():    \n",
        "        name[idx]=key\n",
        "        for age in df.age.unique():  \n",
        "            data_contain= data_contain + df[df.age==age]['valeur phono enfant'].apply(lambda x: [it + f'_{(idx,int(age))}' for it in x]).to_list()\n",
        "        idx+=1\n",
        "    return np.array(*[data_contain]),name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Spec2vec(Pho2Vec): \n",
        "    def __init__(self,data,name):\n",
        "        super().__init__(data)  \n",
        "        self.name=name\n",
        "        self.pho2target={}\n",
        "        self.target2pho={}\n",
        "\n",
        "    \n",
        "    def __toh_all(self,X):  \n",
        "        X = np.vectorize(lambda X: self.pho2int[X])(X)\n",
        "        \n",
        "        return  np.eye(self.vocab_len_input)[X]\n",
        "    \n",
        "    def __toh_target(self,X): \n",
        "        X = np.vectorize(lambda X: self.pho2target[X])(X)\n",
        "        return  np.eye(self.vocab_len_output)[X]\n",
        "\n",
        "\n",
        "    def train_test(self,train_size=0.9,window_size=2): \n",
        "        \n",
        "        self.window_size=window_size\n",
        "        self.data_w2=self.dataforw2c(self.data , self.window_size)\n",
        "        \n",
        "        self.x = [] # input word\n",
        "        self.y= [] # output word\n",
        "        for data_word in self.data_w2:\n",
        "            self.x.append(data_word[0])\n",
        "            self.y.append(data_word[1])\n",
        "        # convert them to numpy arrays\n",
        "        self.x= np.asarray(self.x)\n",
        "        self.y= np.vectorize(lambda x : re.sub(r'\\([^()]*\\)|_', '', x))(np.asarray(self.y)) # Getting rid of specification indice   \n",
        "        \n",
        "        \n",
        "        for i,word in enumerate(np.unique(self.y)):\n",
        "            self.pho2target[word] = i\n",
        "            self.target2pho[i] = word  \n",
        "        self.vocab_len_output=len(self.pho2target)\n",
        "        self.x =self.__toh_all(self.x)\n",
        "        self.y =self.__toh_target(self.y)\n",
        "        \n",
        "        self.x_train,self.x_test,self.y_train,self.y_test =train_test_split(self.x,\n",
        "                                                                           self.y, \n",
        "                                                                           train_size=train_size)  \n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXQreHCnGzAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#d=Spec2vec(*Data4spec2vec(dfdic)) \n",
        "data,name = Data4spec2vec(dfdic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_lCjq-c6pks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyEO6l3JweXb",
        "colab_type": "text"
      },
      "source": [
        "Children class for Colaje use "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-b-yaoDPCyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=Spec2vec(data,name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WuieHciZmZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d.train_test(train_size=0.95,window_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioeFuVj_ZneL",
        "colab_type": "text"
      },
      "source": [
        "Préparation of data for good fromat to Spec2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTJzwLkG7G3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjlutLJIeC54",
        "colab_type": "code",
        "outputId": "a6e98d23-f81f-472b-8295-e3a5b2f825d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d.x.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(295712, 979)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilyhWhc3eQ6Y",
        "colab_type": "code",
        "outputId": "df8deff6-8592-4f59-8de1-de176940fe09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "d.y.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(295712, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JnCyZhKoguE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea317d18-9467-4ce7-b507-e9da16733e84"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.623413251903491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elxc7DjWkCK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72ff7f76-5710-4dca-ba79-0b082aa1c9a6"
      },
      "source": [
        "d.model_2vecbow(embedding_dim=6,n_iter=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "progression : 4100 / 10000  val loss=2.817044496536255  loss = 2.8024048805236816"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0LLyjkq-ilv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc1LohADECKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M3MrudLEQzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5w6wdxbEfdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIu-KniEuGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}